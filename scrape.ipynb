{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the lib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Website\n",
    "first_url = \"https://bygningsreglementet.dk/Administrative-bestemmelser/Krav\"\n",
    "#Using library requests to download index.html (Response=200 is good)\n",
    "response = requests.get(first_url)\n",
    "#Storing the html code\n",
    "html = response.content\n",
    "#Using Beautiful soup to parse the html for pythonformat\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generated a list wiht 43 urls\n"
    }
   ],
   "source": [
    "main_urls=[]\n",
    "#Alle sider\n",
    "for link in soup.nav.find_all(\"a\", {\"class\": \"link-square\"}):\n",
    "  main_urls.append(link[\"href\"])\n",
    "print(\"generated a list wiht\", len(main_urls), \"urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generated a list wiht 21 urls\n"
    }
   ],
   "source": [
    "#there are hidden links which we dont need\n",
    "useful_urls=[]\n",
    "for i in range(21):\n",
    "    useful_urls.append(main_urls[i])\n",
    "print(\"generated a list wiht\", len(useful_urls), \"urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generated a list wiht 134 urls\n"
    }
   ],
   "source": [
    "all_urls=[]\n",
    "#Alle JS expanded pages\n",
    "for link in useful_urls:\n",
    "    response_link = requests.get(link)\n",
    "    html_link = response_link.content\n",
    "    soup_link = BeautifulSoup(html_link, 'html.parser')\n",
    "    for paragraf in soup_link.find_all(\"a\", {\"class\": \"accordion__trigger\"}):\n",
    "        all_urls.append(paragraf[\"href\"])\n",
    "\n",
    "print(\"generated a list wiht\", len(all_urls), \"urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generated a list with 429 paragraffer\n"
    }
   ],
   "source": [
    "paragraf=[]\n",
    "#Alle paragraffer\n",
    "for link in all_urls:\n",
    "    response_link = requests.get(link)\n",
    "    html_link = response_link.content\n",
    "    soup_link = BeautifulSoup(html_link, 'html.parser')\n",
    "\n",
    "    for i in soup_link.find(\"div\", {\"class\": \"accordion__content\"}).find_all(\"div\", {\"class\": \"accordion__tag\"}):\n",
    "        if i.text.strip()!=\"\":\n",
    "            paragraf.append(i.text.strip())\n",
    "        elif i.text.strip()==\"\" and i.div!=None and i.parent.parent.parent.find(\"div\", {\"class\": \"accordion__tag\"}).text.strip()!=\"\" and i.parent[\"class\"]!=['accordion__row', 'accordion__row--footnote-list']:\n",
    "            paragraf.append(i.parent.parent.parent.find(\"div\", {\"class\": \"accordion__tag\"}).text.strip())\n",
    "\n",
    "\n",
    "\n",
    "print(\"generated a list with\", len(paragraf), \"paragraffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-250-d4600c2d477e>, line 9)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-250-d4600c2d477e>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    soup_link.find(\"div\", {\"class\": \"accordion__content\", \"id\"}).find_all(\"div\", {\"class\": \"accordion__content\"})[3].find(\"div\", {\"class\":\"accordion__content\"}).find(\"div\",{\"class\":\"accordion__disclaimer\"}).name==\"div\"\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST TEST \n",
    "\n",
    "\n",
    "link=\"https://bygningsreglementet.dk/Tekniske-bestemmelser/03/Krav/63_68#cb9094f7-1f6c-44c2-8fe0-40ab46bc48fb\"\n",
    "response_link = requests.get(link)\n",
    "html_link = response_link.content\n",
    "soup_link = BeautifulSoup(html_link, 'html.parser')\n",
    "\n",
    "soup_link.find(\"div\", {\"class\": \"accordion__content\"}).find_all(\"div\", {\"class\": \"accordion__content\"})[3].find(\"div\", {\"class\":\"accordion__content\"}).find(\"div\",{\"class\":\"accordion__disclaimer\"}).name==\"div\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "generated a list with 15 beskrivelser\n"
    }
   ],
   "source": [
    "beskrivelse=[]\n",
    "#Alle Beskrivelser\n",
    "for link in all_urls:\n",
    "    response_link = requests.get(link)\n",
    "    html_link = response_link.content\n",
    "    soup_link = BeautifulSoup(html_link, 'html.parser')\n",
    "\n",
    "    for i in soup_link.find(\"div\", {\"class\": \"accordion__content\"}).find_all(\"div\", {\"class\": \"accordion__content\"}):\n",
    "        if i.text.strip()!=\"Se vejledningen her\" and i.parent[\"class\"]!=['accordion__row', 'accordion__row--footnote-list'] and i.parent[\"class\"]!=['accordion__row', 'accordion__row--text']:\n",
    "            beskrivelse.append(i.text.strip())\n",
    "\n",
    "print(\"generated a list with\", len(beskrivelse), \"beskrivelser\")\n",
    "\n",
    "# Class=accordion__content  id=0e7e01f8-cc86-44b3-a046-1f4663536d54 er splittet op i to\n",
    "# Pr√∏v at sortere for id - DS reklamer har ikke et id men det har de andre!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laver en dataframe med al data\n",
    "br18_df=pd.DataFrame({'paragraf': paragraf,'beskrivelse': beskrivelse})\n",
    "br18_df=br18_df.set_index(\"paragraf\")\n",
    "br18_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=pd.DataFrame(paragraf)\n",
    "test2.to_excel(\"test2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda8323ff0e61ae4a6b8857dd46a341f977",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}